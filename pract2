import logging, os
logging.disable(logging.WARNING)
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
from tensorflow import keras

from tensorflow.keras.layers import (
    Dense, Dropout, BatchNormalization, 
    Activation, Conv2D, MaxPooling2D, Flatten
)
from tensorflow.keras.regularizers import l1, l2, l1_l2
from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom
from tensorflow.keras.initializers import HeNormal
import numpy as np
import time
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam, SGD, RMSprop
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from tensorflow.keras.layers import (
    Dense, Dropout, BatchNormalization, Activation, 
    Conv2D, MaxPooling2D, AveragePooling2D, 
    GlobalMaxPooling2D, GlobalAveragePooling2D,
    Flatten, Input
)
from PIL import Image
import os

def cargar_y_preprocesar_cifar10():
    """
    Normalizar los píxeles al rango [0,1] porque ayuda a que la red converja mejor.
    También separo 5000 muestras para validación para poder detectar sobreentrenamiento.
    """
    # Cargar datos
    (x_train, y_train), (x_test, y_test) = cifar10.load_data()
    
    # Normalizar píxeles al rango [0,1]
    x_train = x_train.astype('float32') / 255.0
    x_test = x_test.astype('float32') / 255.0
    
    # Separar conjunto de validación
    val_size = 5000
    x_val = x_train[:val_size]
    y_val = y_train[:val_size]
    x_train = x_train[val_size:]
    y_train = y_train[val_size:]
    
    # Convertir etiquetas a one-hot encoding
    y_train = to_categorical(y_train, 10)
    y_val = to_categorical(y_val, 10)
    y_test = to_categorical(y_test, 10)
    
    # Aplanar imágenes para MLP
    x_train = x_train.reshape(x_train.shape[0], -1)
    x_val = x_val.reshape(x_val.shape[0], -1)
    x_test = x_test.reshape(x_test.shape[0], -1)
    
    print(f"Forma de los datos:")
    print(f"X_train: {x_train.shape}")
    print(f"X_val: {x_val.shape}")
    print(f"X_test: {x_test.shape}")
    
    return x_train, y_train, x_val, y_val, x_test, y_test

def graficar_resultados_experimentos(resultados, tipo='MLP'):
    """
    Función auxiliar para graficar resultados de experimentos
    """
    nombres = list(resultados.keys())
    accuracies = [resultados[n]['val_accuracy'] for n in nombres]
    tiempos = [resultados[n]['tiempo'] for n in nombres]
    
    plt.figure(figsize=(15, 6))
    
    # Gráfica de precisión
    plt.subplot(1, 2, 1)
    barras = plt.bar(range(len(nombres)), accuracies)
    plt.title(f'Precisión de Validación - {tipo}')
    plt.xticks(range(len(nombres)), nombres, rotation=45, ha='right')
    plt.ylabel('Precisión')
    
    # Añadir valores sobre las barras
    for i, bar in enumerate(barras):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{accuracies[i]:.3f}',
                ha='center', va='bottom')
    
    # Gráfica de tiempo
    plt.subplot(1, 2, 2)
    barras = plt.bar(range(len(nombres)), tiempos)
    plt.title(f'Tiempo de Entrenamiento - {tipo}')
    plt.xticks(range(len(nombres)), nombres, rotation=45, ha='right')
    plt.ylabel('Tiempo (s)')
    
    # Añadir valores sobre las barras
    for i, bar in enumerate(barras):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{tiempos[i]:.1f}s',
                ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig(f'resultados/tarea_K_{tipo.lower()}_comparacion.png')
    plt.close()


def graficar_historico_dos_ejes (historicos, titulo, nombre_archivo):
    """
    Creo esta función para visualizar en la misma gráfica tanto la pérdida como la precisión,
    usando dos ejes Y diferentes para que se vean bien las escalas de cada métrica.
    """
    fig, ax1 = plt.subplots(figsize=(10, 6))
    
    if not isinstance(historicos, list):
        historicos = [historicos]  # Convertir a lista si no lo es
    
    # Encontrar la longitud mínima de los historiales
    min_length = min(len(h.history['loss']) for h in historicos)
    
    # Recortar todos los historiales a la longitud mínima
    losses = [h.history['loss'][:min_length] for h in historicos]
    val_losses = [h.history['val_loss'][:min_length] for h in historicos]
    accs = [h.history['accuracy'][:min_length] for h in historicos]
    val_accs = [h.history['val_accuracy'][:min_length] for h in historicos]
    
    # Calcular promedios
    avg_loss = np.mean(losses, axis=0)
    avg_val_loss = np.mean(val_losses, axis=0)
    avg_acc = np.mean(accs, axis=0)
    avg_val_acc = np.mean(val_accs, axis=0)
    
    # Calcular desviaciones estándar
    std_loss = np.std(losses, axis=0)
    std_val_loss = np.std(val_losses, axis=0)
    std_acc = np.std(accs, axis=0)
    std_val_acc = np.std(val_accs, axis=0)
    
    epochs = range(1, min_length + 1)
    
    # Graficar pérdida en el eje izquierdo
    ax1.plot(epochs, avg_loss, 'b-', label='Loss (train)')
    ax1.plot(epochs, avg_val_loss, 'r-', label='Loss (val)')
    ax1.fill_between(epochs, avg_loss - std_loss, avg_loss + std_loss, alpha=0.1, color='b')
    ax1.fill_between(epochs, avg_val_loss - std_val_loss, avg_val_loss + std_val_loss, alpha=0.1, color='r')
    ax1.set_xlabel('Épocas')
    ax1.set_ylabel('Pérdida', color='b')
    ax1.tick_params(axis='y', labelcolor='b')
    
    # Crear segundo eje Y para accuracy
    ax2 = ax1.twinx()
    ax2.plot(epochs, avg_acc, 'g-', label='Accuracy (train)')
    ax2.plot(epochs, avg_val_acc, 'm-', label='Accuracy (val)')
    ax2.fill_between(epochs, avg_acc - std_acc, avg_acc + std_acc, alpha=0.1, color='g')
    ax2.fill_between(epochs, avg_val_acc - std_val_acc, avg_val_acc + std_val_acc, alpha=0.1, color='m')
    ax2.set_ylabel('Precisión', color='g')
    ax2.tick_params(axis='y', labelcolor='g')
    
    # Añadir leyendas
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right')
    
    plt.title(titulo)
    plt.show()
    plt.close()

def crear_grafica_barras(labels, valores, titulo, xlabel, ylabel, nombre_archivo):
    """
    Creación de una gráfica de barras para comparar resultados.
    """
    plt.figure(figsize=(10, 6))
    plt.bar(labels, valores)
    plt.title(titulo)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
    plt.close()

def mostrar_matriz_confusion(model, x_test, y_test, titulo, nombre_archivo):
    """
    Generación de la matriz de confusión.
    """
    y_pred = model.predict(x_test)
    y_pred = np.argmax(y_pred, axis=1)
    y_true = np.argmax(y_test, axis=1)
    
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap='Blues', values_format='d')
    plt.title(titulo)
    plt.show()
    plt.close()
    
    
def cargar_y_preprocesar_cifar10_cnn():
    """
    Carga y preprocesa el dataset CIFAR-10 para CNN.
    """
    (x_train, y_train), (x_test, y_test) = cifar10.load_data()
    
    # Normalizar píxeles al rango [0,1]
    x_train = x_train.astype('float32') / 255.0
    x_test = x_test.astype('float32') / 255.0
    
    # Separar conjunto de validación
    val_size = 5000
    x_val = x_train[:val_size]
    y_val = y_train[:val_size]
    x_train = x_train[val_size:]
    y_train = y_train[val_size:]
    
    y_train = to_categorical(y_train, 10)
    y_val = to_categorical(y_val, 10)
    y_test = to_categorical(y_test, 10)
    
    return x_train, y_train, x_val, y_val, x_test, y_test

def tarea_A(x_train, y_train, x_val, y_val, x_test, y_test):
    """
    Implementa un MLP básico con una capa oculta de 32 neuronas y activación sigmoid.
    Incluye visualizaciones del entrenamiento y matriz de confusión.
    """
    print("\nEjecutando Tarea A: MLP básico")
    
    # Crear el modelo
    model = Sequential([
        Dense(32, activation='sigmoid', input_shape=(x_train.shape[1],)),
        Dense(10, activation='softmax')
    ])
    
    # Compilar el modelo
    model.compile(optimizer=Adam(),
                 loss='categorical_crossentropy',
                 metrics=['accuracy'])
    
    print("\nEstructura del modelo:")
    model.summary()
    
    # Entrenar el modelo y medir tiempo
    inicio = time.time()
    history = model.fit(
        x_train, y_train,
        validation_data=(x_val, y_val),
        epochs=10,
        batch_size=32,
        verbose=1
    )
    tiempo_entrenamiento = time.time() - inicio
    
    # Evaluar el modelo
    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
    
    # Generar visualizaciones
    
    # 1. Gráfica de evolución del entrenamiento
    graficar_historico_dos_ejes(
        history,
        "Entrenamiento MLP básico - Tarea A",
        "tarea_A_historico"
    )
    
    # 2. Matriz de confusión usando el enfoque de la tarea K
    y_pred = model.predict(x_test)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true_classes = np.argmax(y_test, axis=1)
    
    plt.figure(figsize=(10, 8))
    cm = confusion_matrix(y_true_classes, y_pred_classes)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap='Blues')
    plt.title("Matriz de Confusión - MLP básico (Tarea A)")
    plt.savefig('resultados/tarea_A_confusion.png')
    plt.close()
    
    # 3. Gráfica de barras para métricas finales
    plt.figure(figsize=(10, 5))
    
    # Subplot para accuracy
    plt.subplot(1, 2, 1)
    plt.bar(['Test Accuracy'], [test_accuracy])
    plt.title('Precisión en Test')
    plt.ylabel('Accuracy')
    
    # Subplot para tiempo
    plt.subplot(1, 2, 2)
    plt.bar(['Tiempo Entrenamiento'], [tiempo_entrenamiento])
    plt.title('Tiempo de Entrenamiento')
    plt.ylabel('Segundos')
    
    plt.tight_layout()
    plt.savefig('resultados/tarea_A_metricas.png')
    plt.close()
    
    # Imprimir resultados
    print(f"\nResultados Tarea A:")
    print(f"Precisión en test: {test_accuracy:.4f}")
    print(f"Pérdida en test: {test_loss:.4f}")
    print(f"Tiempo de entrenamiento: {tiempo_entrenamiento:.2f} segundos")
    
    return model, history, test_accuracy, tiempo_entrenamiento
def tarea_B(x_train, y_train, x_val, y_val, x_test, y_test):
    """
    Realiza 5 entrenamientos independientes y promedia los resultados para tener una 
    estimación más robusta del rendimiento real del modelo.
    """
    print("\nEjecutando Tarea B: Análisis de sobreentrenamiento")
    
    num_entrenamientos = 5
    historicos = []
    resultados_test = []
    tiempos = []
    modelos = []
    
    for i in range(num_entrenamientos):
        print(f"\nEntrenamiento {i+1}/{num_entrenamientos}")
        
        model = Sequential([
            Dense(32, activation='sigmoid', input_shape=(x_train.shape[1],)),
            Dense(10, activation='softmax')
        ])
        model.compile(optimizer=Adam(), 
                     loss='categorical_crossentropy', 
                     metrics=['accuracy'])
        
        inicio = time.time()
        history = model.fit(
            x_train, y_train,
            validation_data=(x_val, y_val),
            epochs=35,
            batch_size=32,
            verbose=1
        )
        tiempo = time.time() - inicio
        
        test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
        
        historicos.append(history)
        resultados_test.append(test_accuracy)
        tiempos.append(tiempo)
        modelos.append(model)
        
        # Matriz de confusión individual
        mostrar_matriz_confusion(model, x_test, y_test, 
                               f"Matriz de Confusión - Modelo {i+1}", 
                               f"tarea_B_confusion_modelo_{i+1}")
    
    # Calcular promedios y desviaciones
    avg_test_acc = np.mean(resultados_test)
    std_test_acc = np.std(resultados_test)
    avg_tiempo = np.mean(tiempos)
    std_tiempo = np.std(tiempos)
    
    # Mostrar gráfica de evolución del entrenamiento
    graficar_historico_dos_ejes(historicos, 
                               f"Evolución del Entrenamiento (Promedio de {num_entrenamientos} entrenamientos)", 
                               "tarea_B_historico")
    
    # Calcular y mostrar matriz de confusión promedio
    y_pred_all = np.zeros_like(y_test)
    for model in modelos:
        y_pred = model.predict(x_test)
        y_pred_all += y_pred
    y_pred_avg = y_pred_all / num_entrenamientos
    
    y_pred_avg_class = np.argmax(y_pred_avg, axis=1)
    y_true = np.argmax(y_test, axis=1)
    
    # Mostrar matriz de confusión promedio
    plt.figure(figsize=(10, 8))
    cm = confusion_matrix(y_true, y_pred_avg_class)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap='Blues', values_format='d')
    plt.title(f"Matriz de Confusión Promedio ({num_entrenamientos} modelos)")
    plt.savefig('resultados/tarea_B.png')
    plt.close()
    
    print("\nResultados finales (promediados):")
    print(f"Precisión en test: {avg_test_acc:.4f} ± {std_test_acc:.4f}")
    print(f"Tiempo: {avg_tiempo:.2f} ± {std_tiempo:.2f} segundos")
    
    return historicos, resultados_test, tiempos

def tarea_B_opcional(x_train, y_train, x_val, y_val, x_test, y_test):
    """
    Analiza el sobreentrenamiento utilizando early stopping y realizando
    múltiples entrenamientos.
    """
    print("\nEjecutando Tarea B (Opcional): Análisis con Early Stopping")
    
    num_entrenamientos = 5 
    historicos = []
    resultados_test = []
    tiempos = []
    modelos = []
    
    for i in range(num_entrenamientos):
        print(f"\nEntrenamiento {i+1}/{num_entrenamientos}")
        
        model = Sequential([
            Dense(32, activation='sigmoid', input_shape=(x_train.shape[1],)),
            Dense(10, activation='softmax')
        ])
        model.compile(optimizer=Adam(), 
                     loss='categorical_crossentropy', 
                     metrics=['accuracy'])
        
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=4,
            restore_best_weights=True
        )
        
        inicio = time.time()
        history = model.fit(
            x_train, y_train,
            validation_data=(x_val, y_val),
            epochs=35,
            batch_size=32,
            callbacks=[early_stopping],
            verbose=1
        )
        tiempo = time.time() - inicio
        
        test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
        
        historicos.append(history)
        resultados_test.append(test_accuracy)
        tiempos.append(tiempo)
        modelos.append(model)
        
        # Matriz de confusión individual
        mostrar_matriz_confusion(model, x_test, y_test, 
                               f"Matriz de Confusión - Modelo {i+1} con Early Stopping", 
                               f"tarea_B_opcional_confusion_modelo_{i+1}")
    
    # Calcular promedios y desviaciones
    avg_test_acc = np.mean(resultados_test)
    std_test_acc = np.std(resultados_test)
    avg_tiempo = np.mean(tiempos)
    std_tiempo = np.std(tiempos)
    
    # Mostrar gráfica de evolución del entrenamiento
    graficar_historico_dos_ejes(historicos, 
                               "Evolución del Entrenamiento con Early Stopping", 
                               "tarea_B_opcional_historico")
    
    # Calcular y mostrar matriz de confusión promedio
    y_pred_all = np.zeros_like(y_test)
    for model in modelos:
        y_pred = model.predict(x_test)
        y_pred_all += y_pred
    y_pred_avg = y_pred_all / num_entrenamientos
    
    y_pred_avg_class = np.argmax(y_pred_avg, axis=1)
    y_true = np.argmax(y_test, axis=1)
    
    # Mostrar matriz de confusión promedio
    plt.figure(figsize=(10, 8))
    cm = confusion_matrix(y_true, y_pred_avg_class)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap='Blues', values_format='d')
    plt.title(f"Matriz de Confusión Promedio con Early Stopping ({num_entrenamientos} modelos)")
    plt.savefig('resultados/tarea_B_opcional.png')
    plt.close()
    
    print("\nResultados finales con Early Stopping (promediados):")
    print(f"Precisión en test: {avg_test_acc:.4f} ± {std_test_acc:.4f}")
    print(f"Tiempo de entrenamiento: {avg_tiempo:.2f} ± {std_tiempo:.2f} segundos")
    print(f"Número promedio de épocas completadas: {np.mean([len(h.history['loss']) for h in historicos]):.1f}")
    
    return historicos, resultados_test, tiempos

def tarea_C(x_train, y_train, x_val, y_val, x_test, y_test):
    """
    Analiza el efecto del tamaño del batch.
    Ahora incluye matrices de confusión para cada configuración.
    """
    print("\nEjecutando Tarea C: Análisis de batch_size")
    
    batch_sizes = [8, 16, 32, 64, 128, 256, 512]  
    resultados = {}
    
    for batch_size in batch_sizes:
        print(f"\nProbando batch_size={batch_size}")
        
        model = Sequential([
            Dense(32, activation='sigmoid', input_shape=(x_train.shape[1],)),
            Dense(10, activation='softmax')
        ])
        model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

        inicio = time.time()
        history = model.fit(
            x_train, y_train,
            validation_data=(x_val, y_val),
            epochs=30,  
            batch_size=batch_size,
            verbose=1
        )
        tiempo_entrenamiento = time.time() - inicio
        
        test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
        
        resultados[batch_size] = {
            'accuracy': test_accuracy,
            'time': tiempo_entrenamiento,
            'history': history,
            'model': model  # Guardamos el modelo para generar la matriz de confusión
        }
        
        # Generar y guardar matriz de confusión
        y_pred = model.predict(x_test)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true_classes = np.argmax(y_test, axis=1)
        
        plt.figure(figsize=(10, 8))
        cm = confusion_matrix(y_true_classes, y_pred_classes)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues', values_format='d')
        plt.title(f"Matriz de Confusión - Batch Size {batch_size}")
        plt.savefig(f'resultados/tarea_C_confusion_batch_{batch_size}.png')
        plt.close()
        
        # Graficar histórico de entrenamiento
        graficar_historico_dos_ejes([history], 
                                  f"Entrenamiento con batch_size={batch_size}", 
                                  f"tarea_C_historico_{batch_size}")
    
    # Crear gráfica comparativa de precisión y tiempo
    fig, ax1 = plt.subplots(figsize=(12, 6))

    # Gráfica de precisión
    bars = ax1.bar(batch_sizes, [resultados[bs]['accuracy'] for bs in batch_sizes], 
                  color='b', alpha=0.5, label='Precisión')
    ax1.set_xlabel('Tamaño de Batch')
    ax1.set_ylabel('Precisión', color='b')
    ax1.tick_params(axis='y', labelcolor='b')

    # Añadir valores sobre las barras de precisión
    for bar in bars:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.4f}',
                ha='center', va='bottom', color='b')

    # Gráfica de tiempo
    ax2 = ax1.twinx()
    line = ax2.plot(batch_sizes, [resultados[bs]['time'] for bs in batch_sizes], 
                   'r-', label='Tiempo', linewidth=2)
    ax2.set_ylabel('Tiempo (s)', color='r')
    ax2.tick_params(axis='y', labelcolor='r')

    # Añadir valores sobre la línea de tiempo
    for x, y in zip(batch_sizes, [resultados[bs]['time'] for bs in batch_sizes]):
        ax2.text(x, y, f'{y:.1f}s', ha='center', va='bottom', color='r')

    plt.title('Precisión y Tiempo vs Tamaño de Batch')
    
    # Combinar leyendas
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right')

    plt.tight_layout()
    plt.savefig('resultados/tarea_C_comparacion.png')
    plt.close()
    
    # Imprimir resultados
    print("\nResultados Tarea C:")
    for bs in batch_sizes:
        print(f"Batch size {bs}:")
        print(f"  Precisión: {resultados[bs]['accuracy']:.4f}")
        print(f"  Tiempo: {resultados[bs]['time']:.2f} segundos")
    
    return resultados

def tarea_D(x_train, y_train, x_val, y_val, x_test, y_test):
    """
    Prueba de diferentes funciones de activación.
    """
    print("\nEjecutando Tarea D: Análisis de funciones de activación (extendido)")
    
    activaciones = ['sigmoid', 'tanh', 'relu', 'leaky_relu', 'elu', 'selu', 'swish']
    resultados = {}
    
    for activacion in activaciones:
        print(f"\nProbando activación {activacion}")
        
        model = Sequential([
            Dense(32, activation=activacion, input_shape=(x_train.shape[1],)),
            Dense(10, activation='softmax')
        ])
        model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
        
        inicio = time.time()
        history = model.fit(
            x_train, y_train,
            validation_data=(x_val, y_val),
            epochs=15,
            batch_size=32,
            verbose=1
        )
        tiempo_entrenamiento = time.time() - inicio
        
        test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
        
        resultados[activacion] = {
            'accuracy': test_accuracy,
            'time': tiempo_entrenamiento,
            'history': history
        }
        
        # Graficar evolución del entrenamiento
        graficar_historico_dos_ejes([history], 
                                  f"Entrenamiento con activación {activacion}", 
                                  f"tarea_D_historico_{activacion}")
        
        # Generar matriz de confusión con el nuevo enfoque
        y_pred = model.predict(x_test)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true_classes = np.argmax(y_test, axis=1)
        
        plt.figure(figsize=(10, 8))
        cm = confusion_matrix(y_true_classes, y_pred_classes)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues')
        plt.title(f"Matriz de Confusión - Activación {activacion}")
        plt.savefig(f'resultados/tarea_D_confusion_{activacion}.png')
        plt.close()
    
    # Gráficas comparativas
    crear_grafica_barras(
        activaciones,
        [resultados[act]['accuracy'] for act in activaciones],
        'Precisión vs Función de Activación',
        'Función de Activación',
        'Precisión',
        'tarea_D_precision'
    )
    
    crear_grafica_barras(
        activaciones,
        [resultados[act]['time'] for act in activaciones],
        'Tiempo de Entrenamiento vs Función de Activación',
        'Función de Activación',
        'Tiempo (s)',
        'tarea_D_tiempo'
    )
    
    print("\nResultados Tarea D (extendido):")
    for act in activaciones:
        print(f"Activación {act}:")
        print(f"  Precisión: {resultados[act]['accuracy']:.4f}")
        print(f"  Tiempo: {resultados[act]['time']:.2f} segundos")
    
    return resultados

def tarea_E(x_train, y_train, x_val, y_val, x_test, y_test):
    """
    Análisis del efecto del número de neuronas en la capa oculta del MLP.
    """
    print("\nEjecutando Tarea E: Análisis del número de neuronas")
    
    num_neuronas = [8, 16, 32, 64, 128]
    resultados = {}
    
    for neuronas in num_neuronas:
        print(f"\nProbando {neuronas} neuronas en la capa oculta")
        
        model = Sequential([
            Dense(neuronas, activation='relu', input_shape=(x_train.shape[1],)),
            Dense(10, activation='softmax')
        ])
        model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
        
        inicio = time.time()
        history = model.fit(
            x_train, y_train,
            validation_data=(x_val, y_val),
            epochs=10,
            batch_size=32,
            verbose=1
        )
        tiempo_entrenamiento = time.time() - inicio
        
        test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
        
        resultados[neuronas] = {
            'accuracy': test_accuracy,
            'time': tiempo_entrenamiento,
            'history': history
        }
        
        # Graficar evolución del entrenamiento
        graficar_historico_dos_ejes([history], 
                                  f"Entrenamiento con {neuronas} neuronas", 
                                  f"tarea_E_historico_{neuronas}")
        
        # Generar matriz de confusión con el nuevo enfoque
        y_pred = model.predict(x_test)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true_classes = np.argmax(y_test, axis=1)
        
        plt.figure(figsize=(10, 8))
        cm = confusion_matrix(y_true_classes, y_pred_classes)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues')
        plt.title(f"Matriz de Confusión - {neuronas} neuronas")
        plt.savefig(f'resultados/tarea_E_confusion_{neuronas}.png')
        plt.close()
    
    # Gráfica comparativa de precisión y tiempo
    fig, ax1 = plt.subplots(figsize=(10, 6))
    
    ax1.bar(num_neuronas, [resultados[n]['accuracy'] for n in num_neuronas], 
            color='b', alpha=0.5, label='Precisión')
    ax1.set_xlabel('Número de Neuronas')
    ax1.set_ylabel('Precisión', color='b')
    ax1.tick_params(axis='y', labelcolor='b')
    
    ax2 = ax1.twinx()
    ax2.plot(num_neuronas, [resultados[n]['time'] for n in num_neuronas], 
             'r-', label='Tiempo', linewidth=2)
    ax2.set_ylabel('Tiempo (s)', color='r')
    ax2.tick_params(axis='y', labelcolor='r')
    
    plt.title('Precisión y Tiempo vs Número de Neuronas')
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
    
    plt.tight_layout()
    plt.savefig('resultados/tarea_E_comparacion.png')
    plt.close()
    
    # Imprimir resultados
    print("\nResultados Tarea E:")
    for n in num_neuronas:
        print(f"{n} neuronas:")
        print(f"  Precisión: {resultados[n]['accuracy']:.4f}")
        print(f"  Tiempo: {resultados[n]['time']:.2f} segundos")
    
    mejor_modelo = max(resultados.items(), key=lambda x: x[1]['accuracy'] / x[1]['time'])
    print(f"\nMejor modelo: {mejor_modelo[0]} neuronas")
    
    return resultados

def tarea_F(x_train, y_train, x_val, y_val, x_test, y_test):
    """
    Optimiza el modelo secuencial existente añadiendo capas y ajustando parámetros.
    """
    print("\nEjecutando Tarea F: Optimización del modelo secuencial")
    
    # Modelo base
    model_base = Sequential([
        Dense(32, activation='sigmoid', input_shape=(x_train.shape[1],)),
        Dense(10, activation='softmax')
    ])
    model_base.compile(optimizer=Adam(learning_rate=0.001), 
                      loss='categorical_crossentropy', 
                      metrics=['accuracy'])
    
    print("\nEntrenando modelo base...")
    inicio = time.time()
    history_base = model_base.fit(
        x_train, y_train,
        validation_data=(x_val, y_val),
        epochs=15,
        batch_size=32,
        verbose=1
    )
    tiempo_base = time.time() - inicio
    
    test_loss_base, test_accuracy_base = model_base.evaluate(x_test, y_test, verbose=0)
    
    # Matriz de confusión del modelo base
    y_pred_base = model_base.predict(x_test)
    y_pred_base_classes = np.argmax(y_pred_base, axis=1)
    y_true_classes = np.argmax(y_test, axis=1)
    
    plt.figure(figsize=(10, 8))
    cm_base = confusion_matrix(y_true_classes, y_pred_base_classes)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm_base)
    disp.plot(cmap='Blues')
    plt.title("Matriz de Confusión - Modelo Base")
    plt.savefig('resultados/tarea_F_confusion_base.png')
    plt.close()
    
    # Modelo optimizado
    model_optimizado = Sequential([
        Dense(64, activation='relu', input_shape=(x_train.shape[1],)),
        Dense(128, activation='relu'),
        Dense(64, activation='relu'),
        Dense(32, activation='relu'),
        Dense(10, activation='softmax')
    ])
    
    model_optimizado.compile(optimizer=Adam(learning_rate=0.001),
                           loss='categorical_crossentropy',
                           metrics=['accuracy'])
    
    print("\nEntrenando modelo optimizado...")
    inicio = time.time()
    history_optimizado = model_optimizado.fit(
        x_train, y_train,
        validation_data=(x_val, y_val),
        epochs=15,
        batch_size=128,
        verbose=1
    )
    tiempo_optimizado = time.time() - inicio
    
    test_loss_optimizado, test_accuracy_optimizado = model_optimizado.evaluate(x_test, y_test, verbose=0)
    
    # Matriz de confusión del modelo optimizado
    y_pred_opt = model_optimizado.predict(x_test)
    y_pred_opt_classes = np.argmax(y_pred_opt, axis=1)
    
    plt.figure(figsize=(10, 8))
    cm_opt = confusion_matrix(y_true_classes, y_pred_opt_classes)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm_opt)
    disp.plot(cmap='Blues')
    plt.title("Matriz de Confusión - Modelo Optimizado")
    plt.savefig('resultados/tarea_F_confusion_optimizado.png')
    plt.close()
    
    # Gráfica comparativa de la evolución del entrenamiento
    graficar_historico_dos_ejes([history_base, history_optimizado], 
                               "Comparación de Entrenamiento: Modelo Base vs Optimizado", 
                               "tarea_F_historico")
    
    # Comparación de mejora porcentual
    mejora_accuracy = ((test_accuracy_optimizado - test_accuracy_base) / test_accuracy_base) * 100
    mejora_tiempo = ((tiempo_base - tiempo_optimizado) / tiempo_base) * 100
    
    print("\nComparación de resultados:")
    print(f"Modelo base:")
    print(f"  Precisión: {test_accuracy_base:.4f}")
    print(f"  Tiempo: {tiempo_base:.2f} segundos")
    print(f"\nModelo optimizado:")
    print(f"  Precisión: {test_accuracy_optimizado:.4f}")
    print(f"  Tiempo: {tiempo_optimizado:.2f} segundos")
    print(f"\nMejoras:")
    print(f"  Mejora en precisión: {mejora_accuracy:+.2f}%")
    print(f"  Mejora en tiempo: {mejora_tiempo:+.2f}%")
    
    return model_optimizado, history_optimizado, test_accuracy_optimizado, tiempo_optimizado


def tarea_G(x_train, y_train, x_val, y_val, x_test, y_test):
    """
    CNN básica vs CNN con MaxPooling2D.
    """
    print("\nEjecutando Tarea G: CNN básica vs CNN con MaxPooling")
    
    # Modelo CNN básico
    model_basic = Sequential([
        Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        Conv2D(32, (3, 3), activation='relu'),
        Flatten(),
        Dense(10, activation='softmax')
    ])
    
    model_basic.compile(optimizer=Adam(),
                       loss='categorical_crossentropy',
                       metrics=['accuracy'])
    
    inicio = time.time()
    history_basic = model_basic.fit(
        x_train, y_train,
        validation_data=(x_val, y_val),
        epochs=15,
        batch_size=32,
        verbose=1
    )
    tiempo_basic = time.time() - inicio
    
    test_loss_basic, test_accuracy_basic = model_basic.evaluate(x_test, y_test, verbose=0)
    
    # Matriz de confusión para CNN básica
    y_pred_basic = model_basic.predict(x_test)
    y_pred_basic_classes = np.argmax(y_pred_basic, axis=1)
    y_true_classes = np.argmax(y_test, axis=1)
    
    plt.figure(figsize=(10, 8))
    cm_basic = confusion_matrix(y_true_classes, y_pred_basic_classes)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm_basic)
    disp.plot(cmap='Blues')
    plt.title("Matriz de Confusión - CNN básica")
    plt.savefig('resultados/tarea_G_confusion_basic.png')
    plt.close()
    
    # Modelo CNN con MaxPooling
    model_pooling = Sequential([
        Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        MaxPooling2D((2, 2)),
        Conv2D(32, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(10, activation='softmax')
    ])
    
    model_pooling.compile(optimizer=Adam(),
                         loss='categorical_crossentropy',
                         metrics=['accuracy'])
    
    inicio = time.time()
    history_pooling = model_pooling.fit(
        x_train, y_train,
        validation_data=(x_val, y_val),
        epochs=15,
        batch_size=32,
        verbose=1
    )
    tiempo_pooling = time.time() - inicio
    
    test_loss_pooling, test_accuracy_pooling = model_pooling.evaluate(x_test, y_test, verbose=0)
    
    # Matriz de confusión para CNN con MaxPooling
    y_pred_pooling = model_pooling.predict(x_test)
    y_pred_pooling_classes = np.argmax(y_pred_pooling, axis=1)
    
    plt.figure(figsize=(10, 8))
    cm_pooling = confusion_matrix(y_true_classes, y_pred_pooling_classes)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm_pooling)
    disp.plot(cmap='Blues')
    plt.title("Matriz de Confusión - CNN con MaxPooling")
    plt.savefig('resultados/tarea_G_confusion_pooling.png')
    plt.close()
    
    # Gráficas de evolución del entrenamiento
    graficar_historico_dos_ejes([history_basic], 
                               "Entrenamiento CNN básica", 
                               "tarea_G_historico_basic")
    
    graficar_historico_dos_ejes([history_pooling], 
                               "Entrenamiento CNN con MaxPooling", 
                               "tarea_G_historico_pooling")
    
    # Gráfica comparativa
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.bar(['Sin MaxPooling', 'Con MaxPooling'], 
            [test_accuracy_basic, test_accuracy_pooling])
    plt.title('Precisión en Test')
    plt.ylabel('Accuracy')
    
    plt.subplot(1, 2, 2)
    plt.bar(['Sin MaxPooling', 'Con MaxPooling'], 
            [tiempo_basic, tiempo_pooling])
    plt.title('Tiempo de Entrenamiento')
    plt.ylabel('Segundos')
    
    plt.tight_layout()
    plt.savefig('resultados/tarea_G_comparacion.png')
    plt.close()
    
    print("\nComparación de resultados:")
    print(f"CNN básica:")
    print(f"  Precisión: {test_accuracy_basic:.4f}")
    print(f"  Tiempo: {tiempo_basic:.2f} segundos")
    print(f"CNN con MaxPooling:")
    print(f"  Precisión: {test_accuracy_pooling:.4f}")
    print(f"  Tiempo: {tiempo_pooling:.2f} segundos")
    
    return model_pooling, history_pooling, test_accuracy_pooling, tiempo_pooling


def tarea_H(x_train, y_train, x_val, y_val, x_test, y_test):
    """
    Análisis del efecto del tamaño del kernel en las capas Conv2D.
    """
    print("\nEjecutando Tarea H: Análisis de kernel_size")
    
    kernel_sizes = [(3, 3), (5, 5), (7, 7)]
    resultados = {}
    
    for kernel in kernel_sizes:
        nombre = f"kernel_{kernel[0]}x{kernel[1]}"
        print(f"\nProbando {nombre}")
        
        model = Sequential([
            Conv2D(16, kernel, activation='relu', input_shape=(32, 32, 3)),
            MaxPooling2D((2, 2)),
            Conv2D(32, kernel, activation='relu'),
            MaxPooling2D((2, 2)),
            Flatten(),
            Dense(64, activation='relu'),
            Dense(10, activation='softmax')
        ])
        
        model.compile(optimizer=Adam(),
                     loss='categorical_crossentropy',
                     metrics=['accuracy'])
        
        inicio = time.time()
        history = model.fit(x_train, y_train,
                          validation_data=(x_val, y_val),
                          epochs=15,
                          batch_size=32,
                          verbose=1)
        tiempo = time.time() - inicio
        
        test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
        
        resultados[nombre] = {
            'accuracy': test_accuracy,
            'loss': test_loss,
            'tiempo': tiempo,
            'history': history
        }
        
        # Graficar evolución del entrenamiento
        graficar_historico_dos_ejes([history], 
                                  f"Entrenamiento con {nombre}", 
                                  f"tarea_H_historico_{nombre}")
        
        # Generar matriz de confusión
        y_pred = model.predict(x_test)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true_classes = np.argmax(y_test, axis=1)
        
        plt.figure(figsize=(10, 8))
        cm = confusion_matrix(y_true_classes, y_pred_classes)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues')
        plt.title(f"Matriz de Confusión - {nombre}")
        plt.savefig(f'resultados/tarea_H_confusion_{nombre}.png')
        plt.close()
    
    # Gráficas comparativas
    plt.figure(figsize=(12, 5))
    
    nombres = list(resultados.keys())
    precisiones = [resultados[n]['accuracy'] for n in nombres]
    tiempos = [resultados[n]['tiempo'] for n in nombres]
    
    plt.subplot(1, 2, 1)
    plt.bar(nombres, precisiones)
    plt.title('Precisión en Test')
    plt.ylabel('Accuracy')
    plt.xticks(rotation=45)
    
    plt.subplot(1, 2, 2)
    plt.bar(nombres, tiempos)
    plt.title('Tiempo de Entrenamiento')
    plt.ylabel('Segundos')
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    plt.savefig('resultados/tarea_H_comparacion.png')
    plt.close()
    
    print("\nResultados finales:")
    for nombre, resultado in resultados.items():
        print(f"\n{nombre}:")
        print(f"  Precisión: {resultado['accuracy']:.4f}")
        print(f"  Tiempo: {resultado['tiempo']:.2f} segundos")
    
    mejor_kernel = max(resultados.items(), key=lambda x: x[1]['accuracy'])
    print(f"\nMejor modelo: {mejor_kernel[0]}")
    print(f"Precisión: {mejor_kernel[1]['accuracy']:.4f}")
    print(f"Tiempo: {mejor_kernel[1]['tiempo']:.2f} segundos")
    
    return resultados

def tarea_H_opcional(x_train, y_train, x_val, y_val, x_test, y_test):
    """
    Analiza la relación entre kernel_size y MaxPooling.
    """
    print("\nEjecutando análisis opcional de kernel_size y MaxPooling")
    
    kernel_sizes = [(3, 3), (5, 5), (7, 7)]
    resultados = {}
    
    for kernel in kernel_sizes:
        
        # Modelo con MaxPooling
        model_with_pool = Sequential([
            Conv2D(16, kernel, activation='relu', input_shape=(32, 32, 3)),
            MaxPooling2D((2, 2)),
            Conv2D(32, kernel, activation='relu'),
            MaxPooling2D((2, 2)),
            Flatten(),
            Dense(10, activation='softmax')
        ])
        
        model_with_pool.compile(optimizer=Adam(),
                              loss='categorical_crossentropy',
                              metrics=['accuracy'])
        
        # Modelo sin MaxPooling
        model_no_pool = Sequential([
            Conv2D(16, kernel, activation='relu', input_shape=(32, 32, 3)),
            Conv2D(32, kernel, activation='relu'),
            Flatten(),
            Dense(10, activation='softmax')
        ])
        
        model_no_pool.compile(optimizer=Adam(),
                            loss='categorical_crossentropy',
                            metrics=['accuracy'])
        
        # Entrenar modelo con MaxPooling
        inicio = time.time()
        history_pool = model_with_pool.fit(
            x_train, y_train,
            validation_data=(x_val, y_val),
            epochs=15,
            batch_size=32,
            verbose=1
        )
        tiempo_pool = time.time() - inicio
        loss_pool, acc_pool = model_with_pool.evaluate(x_test, y_test, verbose=0)
        
        # Entrenar modelo sin MaxPooling
        inicio = time.time()
        history_no_pool = model_no_pool.fit(
            x_train, y_train,
            validation_data=(x_val, y_val),
            epochs=15,
            batch_size=32,
            verbose=1
        )
        tiempo_no_pool = time.time() - inicio
        loss_no_pool, acc_no_pool = model_no_pool.evaluate(x_test, y_test, verbose=0)
        
        key_pool = f"{kernel[0]}x{kernel[1]}_pool"
        key_no_pool = f"{kernel[0]}x{kernel[1]}_no_pool"
        
        # Matrices de confusión
        # Para modelo con MaxPooling
        y_pred_pool = model_with_pool.predict(x_test)
        y_pred_pool_classes = np.argmax(y_pred_pool, axis=1)
        y_true_classes = np.argmax(y_test, axis=1)
        
        plt.figure(figsize=(10, 8))
        cm_pool = confusion_matrix(y_true_classes, y_pred_pool_classes)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm_pool)
        disp.plot(cmap='Blues')
        plt.title(f"Matriz de Confusión - Kernel {kernel[0]}x{kernel[1]} con MaxPooling")
        plt.savefig(f'resultados/tarea_H_opcional_confusion_{key_pool}.png')
        plt.close()
        
        # Para modelo sin MaxPooling
        y_pred_no_pool = model_no_pool.predict(x_test)
        y_pred_no_pool_classes = np.argmax(y_pred_no_pool, axis=1)
        
        plt.figure(figsize=(10, 8))
        cm_no_pool = confusion_matrix(y_true_classes, y_pred_no_pool_classes)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm_no_pool)
        disp.plot(cmap='Blues')
        plt.title(f"Matriz de Confusión - Kernel {kernel[0]}x{kernel[1]} sin MaxPooling")
        plt.savefig(f'resultados/tarea_H_opcional_confusion_{key_no_pool}.png')
        plt.close()
        
        resultados[key_pool] = {
            'accuracy': acc_pool,
            'time': tiempo_pool,
            'history': history_pool
        }
        
        resultados[key_no_pool] = {
            'accuracy': acc_no_pool,
            'time': tiempo_no_pool,
            'history': history_no_pool
        }
        
        graficar_historico_dos_ejes([history_pool], 
                                  f"Kernel {kernel[0]}x{kernel[1]} con MaxPooling", 
                                  f"opcional_historico_{key_pool}")
        
        graficar_historico_dos_ejes([history_no_pool], 
                                  f"Kernel {kernel[0]}x{kernel[1]} sin MaxPooling", 
                                  f"opcional_historico_{key_no_pool}")
    
    # Gráficas comparativas finales
    plt.figure(figsize=(15, 5))
    
    nombres = list(resultados.keys())
    precisiones = [resultados[n]['accuracy'] for n in nombres]
    tiempos = [resultados[n]['time'] for n in nombres]
    
    plt.subplot(1, 2, 1)
    plt.bar(nombres, precisiones)
    plt.title('Precisión en Test')
    plt.ylabel('Accuracy')
    plt.xticks(rotation=45)
    
    plt.subplot(1, 2, 2)
    plt.bar(nombres, tiempos)
    plt.title('Tiempo de Entrenamiento')
    plt.ylabel('Segundos')
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    plt.savefig('resultados/tarea_H_opcional_comparacion.png')
    plt.close()
    
    print("\nResultados del análisis opcional:")
    for nombre, resultado in resultados.items():
        print(f"\n{nombre}:")
        print(f"  Precisión: {resultado['accuracy']:.4f}")
        print(f"  Tiempo: {resultado['time']:.2f} segundos")
    
    return resultados

def tarea_I(x_train, y_train, x_val, y_val, x_test, y_test):
    """
    Optimizar la arquitectura del modelo CNN.
    """
    print("\nEjecutando Tarea I: Optimización de la arquitectura CNN")
    
    modelos = {
        'baseline': Sequential([
            Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)),
            MaxPooling2D((2, 2)),
            Conv2D(32, (3, 3), activation='relu'),
            MaxPooling2D((2, 2)),
            Flatten(),
            Dense(10, activation='softmax')
        ]),
        'deep': Sequential([
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),
            MaxPooling2D((2, 2)),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            MaxPooling2D((2, 2)),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            MaxPooling2D((2, 2)),
            Flatten(),
            Dense(256, activation='relu'),
            Dense(10, activation='softmax')
        ]),
        'wide': Sequential([
            Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            MaxPooling2D((2, 2)),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            MaxPooling2D((2, 2)),
            Flatten(),
            Dense(256, activation='relu'),
            Dense(10, activation='softmax')
        ])
    }
    
    resultados = {}
    
    for nombre, modelo in modelos.items():
        print(f"\nEntrenando modelo {nombre}")
        
        modelo.compile(optimizer=Adam(learning_rate=0.001),
                      loss='categorical_crossentropy',
                      metrics=['accuracy'])
        
        inicio = time.time()
        history = modelo.fit(
            x_train, y_train,
            validation_data=(x_val, y_val),
            epochs=15,
            batch_size=64,
            verbose=1
        )
        tiempo = time.time() - inicio
        
        test_loss, test_accuracy = modelo.evaluate(x_test, y_test, verbose=0)
        
        resultados[nombre] = {
            'accuracy': test_accuracy,
            'time': tiempo,
            'history': history,
            'model': modelo
        }
        
        # Graficar evolución del entrenamiento
        graficar_historico_dos_ejes([history], 
                                  f"Entrenamiento modelo {nombre}", 
                                  f"tarea_I_historico_{nombre}")
        
        # Generar matriz de confusión
        y_pred = modelo.predict(x_test)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true_classes = np.argmax(y_test, axis=1)
        
        plt.figure(figsize=(10, 8))
        cm = confusion_matrix(y_true_classes, y_pred_classes)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues')
        plt.title(f"Matriz de Confusión - {nombre}")
        plt.savefig(f'resultados/tarea_I_confusion_{nombre}.png')
        plt.close()
    
    # Gráficas comparativas
    plt.figure(figsize=(12, 5))
    
    nombres = list(resultados.keys())
    precisiones = [resultados[n]['accuracy'] for n in nombres]
    tiempos = [resultados[n]['time'] for n in nombres]
    
    plt.subplot(1, 2, 1)
    plt.bar(nombres, precisiones)
    plt.title('Precisión en Test')
    plt.ylabel('Accuracy')
    plt.xticks(rotation=45)
    
    plt.subplot(1, 2, 2)
    plt.bar(nombres, tiempos)
    plt.title('Tiempo de Entrenamiento')
    plt.ylabel('Segundos')
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    plt.savefig('resultados/tarea_I_comparacion.png')
    plt.close()
    
    # Imprimir resultados
    print("\nResultados finales:")
    for nombre, resultado in resultados.items():
        print(f"\nModelo {nombre}:")
        print(f"  Precisión: {resultado['accuracy']:.4f}")
        print(f"  Tiempo: {resultado['time']:.2f} segundos")
    
    mejor_modelo = max(resultados.items(), key=lambda x: x[1]['accuracy'])
    print(f"\nMejor modelo: {mejor_modelo[0]}")
    print(f"Precisión: {mejor_modelo[1]['accuracy']:.4f}")
    print(f"Tiempo: {mejor_modelo[1]['time']:.2f} segundos")
    
    return resultados

def cargar_y_preprocesar_dataset_personalizado(directorio_base='dataset_custom', num_imagenes_requeridas=15):
    """
    Carga y preprocesa el dataset personalizado con validación mejorada
    """
    categorias = ['avion', 'automovil', 'pajaro', 'gato', 'ciervo', 
                 'perro', 'rana', 'caballo', 'barco', 'camion']
    
    X_custom = []
    Y_custom = []
    errores = {}
    
    print("Procesando dataset personalizado...")
    
    # Verificar estructura de directorios
    if not os.path.exists(directorio_base):
        raise ValueError(f"No se encuentra el directorio base: {directorio_base}")
    
    for idx, categoria in enumerate(categorias):
        ruta_categoria = os.path.join(directorio_base, categoria)
        errores_categoria = []
        
        if not os.path.exists(ruta_categoria):
            raise ValueError(f"Falta el directorio para la categoría: {categoria}")
        
        imagenes = [f for f in os.listdir(ruta_categoria) 
                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if len(imagenes) < num_imagenes_requeridas:
            raise ValueError(f"Categoría {categoria}: Se encontraron {len(imagenes)} imágenes, se requieren {num_imagenes_requeridas}")
        
        print(f"\nProcesando {categoria}: {len(imagenes)} imágenes encontradas")
        
        for imagen in imagenes[:num_imagenes_requeridas]:
            try:
                ruta_imagen = os.path.join(ruta_categoria, imagen)
                img = Image.open(ruta_imagen).convert('RGB')
                img = img.resize((32, 32), Image.Resampling.LANCZOS)
                img_array = np.array(img, dtype='float32') / 255.0
                
                X_custom.append(img_array)
                Y_custom.append(idx)
                print(f"  ✓ {imagen}")
            except Exception as e:
                errores_categoria.append((imagen, str(e)))
                print(f"  ✗ Error en {imagen}: {str(e)}")
        
        if errores_categoria:
            errores[categoria] = errores_categoria
    
    if not X_custom:
        raise ValueError("No se pudo cargar ninguna imagen válida")
    
    X_custom = np.array(X_custom)
    Y_custom = np.array(Y_custom)
    Y_custom = to_categorical(Y_custom, 10)
    
    print("\nResumen del dataset:")
    print(f"Total de imágenes: {len(X_custom)}")
    print(f"Forma de los datos: {X_custom.shape}")
    print(f"Rango de valores: [{X_custom.min():.3f}, {X_custom.max():.3f}]")
    
    if errores:
        print("\nErrores encontrados:")
        for categoria, err_list in errores.items():
            print(f"{categoria}: {len(err_list)} errores")
            for img, err in err_list:
                print(f"  - {img}: {err}")
    
    return X_custom, Y_custom

def tarea_J(directorio_base='dataset_custom'):
    """
    Crea y evalúa el dataset personalizado.
    
    El dataset debe contener:
    - 15 imágenes por cada una de las 10 categorías
    - Imágenes en formato 32x32 píxeles en color
    - Categorías: avión, automóvil, pájaro, gato, ciervo, perro, rana, caballo, barco y camión
    """
    print("\nEjecutando Tarea J: Dataset personalizado")
    
    # Crear directorio para resultados si no existe
    if not os.path.exists('resultados'):
        os.makedirs('resultados')
    
    try:
        categorias = ['avion', 'automovil', 'pajaro', 'gato', 'ciervo', 
                     'perro', 'rana', 'caballo', 'barco', 'camion']
        
        X_custom = []
        Y_custom = []
        resumen_dataset = {}
        
        print("\nProcesando dataset personalizado...")
        
        # Verificar estructura de directorios
        if not os.path.exists(directorio_base):
            raise ValueError(f"No se encuentra el directorio base: {directorio_base}")
        
        for idx, categoria in enumerate(categorias):
            ruta_categoria = os.path.join(directorio_base, categoria)
            
            if not os.path.exists(ruta_categoria):
                raise ValueError(f"Falta el directorio para la categoría: {categoria}")
            
            imagenes = [f for f in os.listdir(ruta_categoria) 
                       if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            if len(imagenes) < 15:
                raise ValueError(f"Categoría {categoria}: Se encontraron {len(imagenes)} imágenes, se requieren 15")
            
            print(f"\nProcesando {categoria}:")
            imagenes_procesadas = 0
            
            for imagen in imagenes[:15]:
                try:
                    ruta_imagen = os.path.join(ruta_categoria, imagen)
                    img = Image.open(ruta_imagen).convert('RGB')
                    img = img.resize((32, 32), Image.Resampling.LANCZOS)
                    img_array = np.array(img, dtype='float32') / 255.0
                    
                    X_custom.append(img_array)
                    Y_custom.append(idx)
                    imagenes_procesadas += 1
                    print(f"  ✓ {imagen}")
                    
                except Exception as e:
                    print(f"  ✗ Error procesando {imagen}: {str(e)}")
            
            resumen_dataset[categoria] = imagenes_procesadas
        
        if not X_custom:
            raise ValueError("No se pudo cargar ninguna imagen válida")
        
        X_custom = np.array(X_custom)
        Y_custom = np.array(Y_custom)
        Y_custom = to_categorical(Y_custom, 10)
        
        # Mostrar resumen del dataset
        print("\nResumen del dataset creado:")
        print(f"Dimensiones de X_custom: {X_custom.shape}")
        print(f"Dimensiones de Y_custom: {Y_custom.shape}")
        print("\nImágenes por categoría:")
        for categoria, cantidad in resumen_dataset.items():
            print(f"{categoria}: {cantidad} imágenes")
        
        # Visualizar ejemplos del dataset
        plt.figure(figsize=(15, 10))
        
        for i in range(10):
            indices = np.where(np.argmax(Y_custom, axis=1) == i)[0]
            if len(indices) > 0:
                plt.subplot(2, 5, i+1)
                plt.imshow(X_custom[indices[0]])
                plt.title(categorias[i])
                plt.axis('off')
        
        plt.suptitle("Ejemplos del Dataset Personalizado")
        plt.tight_layout()
        plt.savefig('resultados/tarea_J_ejemplos.png')
        plt.close()
        
        # Visualizar distribución de clases
        plt.figure(figsize=(12, 6))
        plt.bar(categorias, [resumen_dataset[cat] for cat in categorias])
        plt.title('Distribución de Clases en el Dataset')
        plt.xticks(rotation=45)
        plt.ylabel('Número de imágenes')
        plt.tight_layout()
        plt.savefig('resultados/tarea_J_distribucion.png')
        plt.close()
        
        return X_custom, Y_custom
        
    except Exception as e:
        print(f"\nError en la Tarea J: {str(e)}")
        return None, None



def tarea_K(X_custom, Y_custom):
    """
    Análisis exhaustivo de parámetros configurables sobre el dataset personalizado.
    Experimenta con:
    1. Tamaño y profundidad de capas ocultas
    2. Funciones de activación
    3. Optimizadores y learning rates
    4. Número de iteraciones y batch size
    5. Tamaño de filtros en capas Conv2D
    """
    print("\nEjecutando Tarea K: Análisis completo de parámetros")
    
    # Preparar datos
    X_custom_flat = X_custom.reshape(X_custom.shape[0], -1)
    resultados_experimentos = {}
    
    # 1. EXPERIMENTO: TAMAÑO Y PROFUNDIDAD DE CAPAS
    print("\n1. Analizando tamaño y profundidad de capas...")
    arquitecturas = {
        'una_capa_32': [32],
        'una_capa_64': [64],
        'dos_capas_32_16': [32, 16],
        'dos_capas_64_32': [64, 32],
        'tres_capas_64_32_16': [64, 32, 16],
        'profunda_128_64_32_16': [128, 64, 32, 16]
    }
    
    for nombre, capas in arquitecturas.items():
        print(f"\nProbando arquitectura: {nombre}")
        model = Sequential()
        
        # Primera capa
        model.add(Dense(capas[0], activation='relu', input_shape=(3072,)))
        
        # Capas intermedias
        for neuronas in capas[1:]:
            model.add(Dense(neuronas, activation='relu'))
        
        # Capa de salida
        model.add(Dense(10, activation='softmax'))
        
        model.compile(optimizer=Adam(),
                     loss='categorical_crossentropy',
                     metrics=['accuracy'])
        
        inicio = time.time()
        history = model.fit(X_custom_flat, Y_custom,
                          validation_split=0.2,
                          epochs=15,
                          batch_size=32,
                          verbose=1)
        tiempo = time.time() - inicio
        
        loss, accuracy = model.evaluate(X_custom_flat, Y_custom, verbose=0)
        resultados_experimentos[f'capas_{nombre}'] = {
            'accuracy': accuracy,
            'loss': loss,
            'tiempo': tiempo,
            'history': history
        }
        
        # Visualizaciones
        graficar_historico_dos_ejes(history,
                                  f"Entrenamiento - Arquitectura {nombre}",
                                  f"tarea_K_capas_{nombre}")
        
        # Matriz de confusión
        y_pred = model.predict(X_custom_flat)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true_classes = np.argmax(Y_custom, axis=1)
        
        plt.figure(figsize=(10, 8))
        cm = confusion_matrix(y_true_classes, y_pred_classes)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues')
        plt.title(f"Matriz de Confusión - Arquitectura {nombre}")
        plt.savefig(f'resultados/tarea_K_confusion_capas_{nombre}.png')
        plt.close()
    
    # 2. EXPERIMENTO: FUNCIONES DE ACTIVACIÓN
    print("\n2. Analizando funciones de activación...")
    activaciones = ['relu', 'tanh', 'sigmoid', 'elu', 'selu']
    
    for activacion in activaciones:
        print(f"\nProbando activación: {activacion}")
        model = Sequential([
            Dense(64, activation=activacion, input_shape=(3072,)),
            Dense(32, activation=activacion),
            Dense(10, activation='softmax')
        ])
        
        model.compile(optimizer=Adam(),
                     loss='categorical_crossentropy',
                     metrics=['accuracy'])
        
        inicio = time.time()
        history = model.fit(X_custom_flat, Y_custom,
                          validation_split=0.2,
                          epochs=15,
                          batch_size=32,
                          verbose=1)
        tiempo = time.time() - inicio
        
        loss, accuracy = model.evaluate(X_custom_flat, Y_custom, verbose=0)
        resultados_experimentos[f'activacion_{activacion}'] = {
            'accuracy': accuracy,
            'loss': loss,
            'tiempo': tiempo,
            'history': history
        }
        
        graficar_historico_dos_ejes(history,
                                  f"Entrenamiento - Activación {activacion}",
                                  f"tarea_K_activacion_{activacion}")
        
        # Matriz de confusión
        y_pred = model.predict(X_custom_flat)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true_classes = np.argmax(Y_custom, axis=1)
        
        plt.figure(figsize=(10, 8))
        cm = confusion_matrix(y_true_classes, y_pred_classes)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues')
        plt.title(f"Matriz de Confusión - Activación {activacion}")
        plt.savefig(f'resultados/tarea_K_confusion_activacion_{activacion}.png')
        plt.close()
        
    # 3. EXPERIMENTO: OPTIMIZADORES Y LEARNING RATES
    print("\n3. Analizando optimizadores y learning rates...")
    optimizadores = [
        ('Adam_001', Adam(learning_rate=0.01)),
        ('Adam_0001', Adam(learning_rate=0.001)),
        ('Adam_00001', Adam(learning_rate=0.0001)),
        ('SGD_001', SGD(learning_rate=0.01)),
        ('SGD_0001', SGD(learning_rate=0.001)),
        ('RMSprop_001', RMSprop(learning_rate=0.01)),
        ('RMSprop_0001', RMSprop(learning_rate=0.001))
    ]
    
    for nombre, optimizador in optimizadores:
        print(f"\nProbando optimizador: {nombre}")
        model = Sequential([
            Dense(64, activation='relu', input_shape=(3072,)),
            Dense(32, activation='relu'),
            Dense(10, activation='softmax')
        ])
        
        model.compile(optimizer=optimizador,
                     loss='categorical_crossentropy',
                     metrics=['accuracy'])
        
        inicio = time.time()
        history = model.fit(X_custom_flat, Y_custom,
                          validation_split=0.2,
                          epochs=15,
                          batch_size=32,
                          verbose=1)
        tiempo = time.time() - inicio
        
        loss, accuracy = model.evaluate(X_custom_flat, Y_custom, verbose=0)
        resultados_experimentos[f'optimizador_{nombre}'] = {
            'accuracy': accuracy,
            'loss': loss,
            'tiempo': tiempo,
            'history': history
        }
        
        graficar_historico_dos_ejes(history,
                                  f"Entrenamiento - Optimizador {nombre}",
                                  f"tarea_K_optim_{nombre}")
        
        # Matriz de confusión
        y_pred = model.predict(X_custom_flat)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true_classes = np.argmax(Y_custom, axis=1)
        
        plt.figure(figsize=(10, 8))
        cm = confusion_matrix(y_true_classes, y_pred_classes)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues')
        plt.title(f"Matriz de Confusión - Optimizador {nombre}")
        plt.savefig(f'resultados/tarea_K_confusion_optimizador_{nombre}.png')
        plt.close()
        
        
    # 4. EXPERIMENTO: EPOCHS Y BATCH SIZE
    print("\n4. Analizando epochs y batch size...")
    epochs_list = [10, 20, 30]
    batch_sizes = [16, 32, 64, 128]
    
    for epochs in epochs_list:
        for batch_size in batch_sizes:
            nombre = f"ep{epochs}_batch{batch_size}"
            print(f"\nProbando {nombre}")
            
            model = Sequential([
                Dense(64, activation='relu', input_shape=(3072,)),
                Dense(32, activation='relu'),
                Dense(10, activation='softmax')
            ])
            
            model.compile(optimizer=Adam(),
                         loss='categorical_crossentropy',
                         metrics=['accuracy'])
            
            inicio = time.time()
            history = model.fit(X_custom_flat, Y_custom,
                              validation_split=0.2,
                              epochs=epochs,
                              batch_size=batch_size,
                              verbose=1)
            tiempo = time.time() - inicio
            
            loss, accuracy = model.evaluate(X_custom_flat, Y_custom, verbose=0)
            resultados_experimentos[f'epochs_batch_{nombre}'] = {
                'accuracy': accuracy,
                'loss': loss,
                'tiempo': tiempo,
                'history': history
            }
            
            graficar_historico_dos_ejes(history,
                                      f"Entrenamiento - {nombre}",
                                      f"tarea_K_epochs_{nombre}")
            
            # Matriz de confusión
            y_pred = model.predict(X_custom_flat)
            y_pred_classes = np.argmax(y_pred, axis=1)
            y_true_classes = np.argmax(Y_custom, axis=1)
            
            plt.figure(figsize=(10, 8))
            cm = confusion_matrix(y_true_classes, y_pred_classes)
            disp = ConfusionMatrixDisplay(confusion_matrix=cm)
            disp.plot(cmap='Blues')
            plt.title(f"Matriz de Confusión - {nombre}")
            plt.savefig(f'resultados/tarea_K_confusion_epochs_batch_{nombre}.png')
            plt.close()
    
    # 5. EXPERIMENTO: TAMAÑOS DE FILTRO CNN
    print("\n5. Analizando tamaños de filtro CNN...")
    kernel_sizes = [(3, 3), (5, 5), (7, 7)]
    
    for kernel in kernel_sizes:
        nombre = f"kernel_{kernel[0]}x{kernel[1]}"
        print(f"\nProbando {nombre}")
        
        model = Sequential([
            Conv2D(16, kernel, activation='relu', input_shape=(32, 32, 3)),
            MaxPooling2D((2, 2)),
            Conv2D(32, kernel, activation='relu'),
            MaxPooling2D((2, 2)),
            Flatten(),
            Dense(64, activation='relu'),
            Dense(10, activation='softmax')
        ])
        
        model.compile(optimizer=Adam(),
                     loss='categorical_crossentropy',
                     metrics=['accuracy'])
        
        inicio = time.time()
        history = model.fit(X_custom, Y_custom,
                          validation_split=0.2,
                          epochs=15,
                          batch_size=32,
                          verbose=1)
        tiempo = time.time() - inicio
        
        loss, accuracy = model.evaluate(X_custom, Y_custom, verbose=0)
        resultados_experimentos[f'cnn_{nombre}'] = {
            'accuracy': accuracy,
            'loss': loss,
            'tiempo': tiempo,
            'history': history
        }
        
        graficar_historico_dos_ejes(history,
                                  f"Entrenamiento - CNN {nombre}",
                                  f"tarea_K_cnn_{nombre}")
        
        # Matriz de confusión - Nota que aquí usamos X_custom en lugar de X_custom_flat
        y_pred = model.predict(X_custom)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true_classes = np.argmax(Y_custom, axis=1)
        
        plt.figure(figsize=(10, 8))
        cm = confusion_matrix(y_true_classes, y_pred_classes)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues')
        plt.title(f"Matriz de Confusión - CNN {nombre}")
        plt.savefig(f'resultados/tarea_K_confusion_cnn_{nombre}.png')
        plt.close()
    
    # Crear tabla resumen
    print("\nGenerando tabla resumen...")
    tabla_resumen = {
        'Configuración': [],
        'Precisión': [],
        'Pérdida': [],
        'Tiempo (s)': []
    }
    
    for nombre, resultado in resultados_experimentos.items():
        tabla_resumen['Configuración'].append(nombre)
        tabla_resumen['Precisión'].append(f"{resultado['accuracy']:.4f}")
        tabla_resumen['Pérdida'].append(f"{resultado['loss']:.4f}")
        tabla_resumen['Tiempo (s)'].append(f"{resultado['tiempo']:.2f}")
    
    # Guardar tabla en CSV
    import pandas as pd
    df = pd.DataFrame(tabla_resumen)
    df.to_csv('resultados/tarea_K_resumen.csv', index=False)
    
    # Crear gráfica comparativa final
    plt.figure(figsize=(15, 10))
    
    # Gráfica de precisión
    plt.subplot(2, 1, 1)
    acc_values = [float(v) for v in tabla_resumen['Precisión']]
    plt.bar(range(len(acc_values)), acc_values)
    plt.title('Precisión por Configuración')
    plt.xticks(range(len(acc_values)), tabla_resumen['Configuración'], rotation=45, ha='right')
    plt.ylabel('Precisión')
    
    # Gráfica de tiempo
    plt.subplot(2, 1, 2)
    time_values = [float(v) for v in tabla_resumen['Tiempo (s)']]
    plt.bar(range(len(time_values)), time_values)
    plt.title('Tiempo de Entrenamiento por Configuración')
    plt.xticks(range(len(time_values)), tabla_resumen['Configuración'], rotation=45, ha='right')
    plt.ylabel('Tiempo (s)')
    
    plt.tight_layout()
    plt.savefig('resultados/tarea_K_comparacion_final.png')
    plt.close()
    
    # Encontrar mejor configuración
    mejor_config = max(resultados_experimentos.items(),
                      key=lambda x: x[1]['accuracy'])
    
    print("\nMejor configuración encontrada:")
    print(f"Configuración: {mejor_config[0]}")
    print(f"Precisión: {mejor_config[1]['accuracy']:.4f}")
    print(f"Pérdida: {mejor_config[1]['loss']:.4f}")
    print(f"Tiempo: {mejor_config[1]['tiempo']:.2f} segundos")
    
    return resultados_experimentos, mejor_config



def tarea_L(X_custom, Y_custom):
    """
    Implementa y evalúa diferentes técnicas para mejorar la generalización:
    1. Pooling
    2. Regularización (L1/L2, Dropout)
    3. Data Augmentation
    4. Batch Normalization
    5. Inicialización de pesos
    """
    print("\nEjecutando Tarea L: Mejoras de generalización")
    
    if not os.path.exists('resultados'):
        os.makedirs('resultados')
    
    resultados = {}
    
    # Asegurar forma correcta de los datos
    if len(X_custom.shape) == 3:
        X_custom = X_custom.reshape(-1, 32, 32, 3)
    X_flat = X_custom.reshape(X_custom.shape[0], -1)
    
    # 1. MODELO BASE
    print("\n1. Entrenando modelo base...")
    model_base = Sequential([
        Dense(64, activation='relu', input_shape=(3072,)),
        Dense(32, activation='relu'),
        Dense(10, activation='softmax')
    ])
    
    model_base.compile(optimizer=Adam(),
                      loss='categorical_crossentropy',
                      metrics=['accuracy'])
    
    inicio = time.time()
    history_base = model_base.fit(X_flat, Y_custom,
                                validation_split=0.2,
                                epochs=15,
                                batch_size=32,
                                verbose=1)
    tiempo_base = time.time() - inicio
    
    _, val_acc_base = model_base.evaluate(X_flat, Y_custom, verbose=0)
    resultados['base'] = {
        'val_accuracy': val_acc_base,
        'tiempo': tiempo_base,
        'history': history_base,
        'model': model_base
    }
    
    # 2. POOLING
    print("\n2. Probando diferentes tipos de Pooling...")
    
    # MaxPooling
    model_maxpool = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        MaxPooling2D(pool_size=(2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(pool_size=(2, 2)),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(10, activation='softmax')
    ])
    
    model_maxpool.compile(optimizer=Adam(),
                         loss='categorical_crossentropy',
                         metrics=['accuracy'])
    
    inicio = time.time()
    history_maxpool = model_maxpool.fit(X_custom, Y_custom,
                                      validation_split=0.2,
                                      epochs=15,
                                      batch_size=32,
                                      verbose=1)
    tiempo_maxpool = time.time() - inicio
    
    _, val_acc_maxpool = model_maxpool.evaluate(X_custom, Y_custom, verbose=0)
    resultados['maxpool'] = {
        'val_accuracy': val_acc_maxpool,
        'tiempo': tiempo_maxpool,
        'history': history_maxpool,
        'model': model_maxpool
    }
    
    # AveragePooling
    model_avgpool = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        AveragePooling2D(pool_size=(2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        AveragePooling2D(pool_size=(2, 2)),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(10, activation='softmax')
    ])
    
    model_avgpool.compile(optimizer=Adam(),
                         loss='categorical_crossentropy',
                         metrics=['accuracy'])
    
    inicio = time.time()
    history_avgpool = model_avgpool.fit(X_custom, Y_custom,
                                      validation_split=0.2,
                                      epochs=15,
                                      batch_size=32,
                                      verbose=1)
    tiempo_avgpool = time.time() - inicio
    
    _, val_acc_avgpool = model_avgpool.evaluate(X_custom, Y_custom, verbose=0)
    resultados['avgpool'] = {
        'val_accuracy': val_acc_avgpool,
        'tiempo': tiempo_avgpool,
        'history': history_avgpool,
        'model': model_avgpool
    }
    
    # 3. REGULARIZACIÓN
    print("\n3. Probando técnicas de regularización...")
    
    # Dropout
    model_dropout = Sequential([
        Dense(64, activation='relu', input_shape=(3072,)),
        Dropout(0.3),
        Dense(32, activation='relu'),
        Dropout(0.2),
        Dense(10, activation='softmax')
    ])
    
    model_dropout.compile(optimizer=Adam(),
                        loss='categorical_crossentropy',
                        metrics=['accuracy'])
    
    inicio = time.time()
    history_dropout = model_dropout.fit(X_flat, Y_custom,
                                      validation_split=0.2,
                                      epochs=15,
                                      batch_size=32,
                                      verbose=1)
    tiempo_dropout = time.time() - inicio
    
    _, val_acc_dropout = model_dropout.evaluate(X_flat, Y_custom, verbose=0)
    resultados['dropout'] = {
        'val_accuracy': val_acc_dropout,
        'tiempo': tiempo_dropout,
        'history': history_dropout,
        'model': model_dropout
    }
    
    # L1L2 Regularización
    model_l1l2 = Sequential([
        Dense(64, activation='relu',
              kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4),
              input_shape=(3072,)),
        Dense(32, activation='relu',
              kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),
        Dense(10, activation='softmax')
    ])
    
    model_l1l2.compile(optimizer=Adam(),
                      loss='categorical_crossentropy',
                      metrics=['accuracy'])
    
    inicio = time.time()
    history_l1l2 = model_l1l2.fit(X_flat, Y_custom,
                                 validation_split=0.2,
                                 epochs=15,
                                 batch_size=32,
                                 verbose=1)
    tiempo_l1l2 = time.time() - inicio
    
    _, val_acc_l1l2 = model_l1l2.evaluate(X_flat, Y_custom, verbose=0)
    resultados['l1l2'] = {
        'val_accuracy': val_acc_l1l2,
        'tiempo': tiempo_l1l2,
        'history': history_l1l2,
        'model': model_l1l2
    }
    
    # 4. DATA AUGMENTATION
    print("\n4. Probando Data Augmentation...")
    data_augmentation = Sequential([
        RandomFlip("horizontal"),
        RandomRotation(0.1),
        RandomZoom(0.1),
    ])
    
    model_aug = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(10, activation='softmax')
    ])
    
    model_aug.compile(optimizer=Adam(),
                     loss='categorical_crossentropy',
                     metrics=['accuracy'])
    
    inicio = time.time()
    augmented_data = data_augmentation(X_custom)
    history_aug = model_aug.fit(augmented_data, Y_custom,
                               validation_split=0.2,
                               epochs=15,
                               batch_size=32,
                               verbose=1)
    tiempo_aug = time.time() - inicio
    
    _, val_acc_aug = model_aug.evaluate(X_custom, Y_custom, verbose=0)
    resultados['augmentation'] = {
        'val_accuracy': val_acc_aug,
        'tiempo': tiempo_aug,
        'history': history_aug,
        'model': model_aug
    }
    
    # 5. BATCH NORMALIZATION
    print("\n5. Probando Batch Normalization...")
    model_bn = Sequential([
        Dense(64, input_shape=(3072,)),
        BatchNormalization(),
        Activation('relu'),
        Dense(32),
        BatchNormalization(),
        Activation('relu'),
        Dense(10, activation='softmax')
    ])
    
    model_bn.compile(optimizer=Adam(),
                    loss='categorical_crossentropy',
                    metrics=['accuracy'])
    
    inicio = time.time()
    history_bn = model_bn.fit(X_flat, Y_custom,
                             validation_split=0.2,
                             epochs=15,
                             batch_size=32,
                             verbose=1)
    tiempo_bn = time.time() - inicio
    
    _, val_acc_bn = model_bn.evaluate(X_flat, Y_custom, verbose=0)
    resultados['batch_norm'] = {
        'val_accuracy': val_acc_bn,
        'tiempo': tiempo_bn,
        'history': history_bn,
        'model': model_bn
    }
    
    # Visualizar resultados
    print("\nGenerando visualizaciones...")
    for nombre, resultado in resultados.items():
        # Gráfica de entrenamiento
        graficar_historico_dos_ejes(resultado['history'],
                                  f"Entrenamiento - {nombre}",
                                  f"tarea_L_{nombre}")
        
        # Matriz de confusión
        if 'model' in resultado:
            x_eval = X_flat if 'Conv' not in str(resultado['model'].layers[0].__class__) else X_custom
            y_pred = resultado['model'].predict(x_eval)
            y_pred_classes = np.argmax(y_pred, axis=1)
            y_true_classes = np.argmax(Y_custom, axis=1)
            
            plt.figure(figsize=(10, 8))
            cm = confusion_matrix(y_true_classes, y_pred_classes)
            disp = ConfusionMatrixDisplay(confusion_matrix=cm)
            disp.plot(cmap='Blues')
            plt.title(f"Matriz de Confusión - {nombre}")
            plt.savefig(f'resultados/tarea_L_confusion_{nombre}.png')
            plt.close()
    
    # Crear tabla comparativa
    tabla_resumen = pd.DataFrame({
        'Técnica': list(resultados.keys()),
        'Precisión': [r['val_accuracy'] for r in resultados.values()],
        'Tiempo (s)': [r['tiempo'] for r in resultados.values()]
    })
    
    tabla_resumen.to_csv('resultados/tarea_L_resumen.csv', index=False)
    
    # Gráfica comparativa
    plt.figure(figsize=(15, 6))
    
    # Precisión
    plt.subplot(1, 2, 1)
    plt.bar(tabla_resumen['Técnica'], tabla_resumen['Precisión'])
    plt.title('Precisión por Técnica')
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Precisión')
    
    # Tiempo
    plt.subplot(1, 2, 2)
    plt.bar(tabla_resumen['Técnica'], tabla_resumen['Tiempo (s)'])
    plt.title('Tiempo de Entrenamiento por Técnica')
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Tiempo (s)')
    
    plt.tight_layout()
    plt.savefig('resultados/tarea_L_comparacion.png')
    plt.close()
    
    # Encontrar mejor técnica
    mejor_tecnica = max(resultados.items(), key=lambda x: x[1]['val_accuracy'])
    
    print("\nResumen de resultados:")
    for tecnica, resultado in resultados.items():
        print(f"\n{tecnica}:")
        print(f"  Precisión: {resultado['val_accuracy']:.4f}")
        print(f"  Tiempo: {resultado['tiempo']:.2f} segundos")
    
    print(f"\nMejor técnica: {mejor_tecnica[0]}")
    print(f"Precisión: {mejor_tecnica[1]['val_accuracy']:.4f}")
    print(f"Tiempo: {mejor_tecnica[1]['tiempo']:.2f} segundos")
    
    return resultados, mejor_tecnica



if __name__ == "__main__":
    
    # Cargar y preprocesar datos una única vez
    print("Cargando y preprocesando datos...")
    
    # Descomentar para las tareas A, B, C, D, E, F, K, J, L
    X_train, Y_train, X_val, Y_val, X_test, Y_test = cargar_y_preprocesar_cifar10()
    
    # Descomentar para las tareas G, H e I
    # X_train, Y_train, X_val, Y_val, X_test, Y_test = cargar_y_preprocesar_cifar10_cnn()
    
    
    # Ejecutar tareas (descomentar la que se quiera ejecutar)
    
    # Tarea A - MLP básico
    # modelA, historyA, accA, timeA = tarea_A(X_train, Y_train, X_val, Y_val, X_test, Y_test)
    
    # Tarea B
    # historicos, resultados_test, tiempos = tarea_B(X_train, Y_train, X_val, Y_val, X_test, Y_test)
    
    # Tarea B - Opcional - Análisis de sobreentrenamiento
    # historicos, resultados_test, tiempos = tarea_B_opcional(X_train, Y_train, X_val, Y_val, X_test, Y_test)
    
    # Tarea C - Análisis de batch_size
    resultadosC = tarea_C(X_train, Y_train, X_val, Y_val, X_test, Y_test)
    
    # Tarea D - Análisis de funciones de activación
    # resultadosD = tarea_D(X_train, Y_train, X_val, Y_val, X_test, Y_test)
    
    # Tarea E - Análisis del número de neuronas
    # resultadosE = tarea_E(X_train, Y_train, X_val, Y_val, X_test, Y_test)
    
    # Tarea F - Optimización de la arquitectura del modelo
    # resultadosF = tarea_F(X_train, Y_train, X_val, Y_val, X_test, Y_test)
    
    #############################
    
    # Tarea G
    # modelG, historyG, accG, timeG = tarea_G(X_train, Y_train, X_val, Y_val, X_test, Y_test)
    
    # Tarea H
    # resultadosH = tarea_H(X_train, Y_train, X_val, Y_val, X_test, Y_test)
    
    # Tarea H - Opcional
    # resultadosH_opcional = tarea_H_opcional(X_train, Y_train, X_val, Y_val, X_test, Y_test)
    
    # Tarea I
    # resultadosI = tarea_I(X_train, Y_train, X_val, Y_val, X_test, Y_test)
    
    #############################
    
    # Tarea J - Dataset personalizado
    # X_custom, Y_custom = tarea_J()

    # Tarea K 
    # resultados_mlp, mejor_config_mlp = tarea_K(X_custom, Y_custom)

     # Tarea L
    # resultados, mejor_tecnica = tarea_L(X_custom, Y_custom)
